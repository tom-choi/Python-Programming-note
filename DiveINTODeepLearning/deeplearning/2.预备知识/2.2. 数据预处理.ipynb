{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abeac49d",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 数据预处理\n",
    ":label:`sec_pandas`\n",
    "\n",
    "为了能用深度学习来解决现实世界的问题，我们经常从预处理原始数据开始，\n",
    "而不是从那些准备好的张量格式数据开始。\n",
    "在Python中常用的数据分析工具中，我们通常使用`pandas`软件包。\n",
    "像庞大的Python生态系统中的许多其他扩展包一样，`pandas`可以与张量兼容。\n",
    "本节我们将简要介绍使用`pandas`预处理原始数据，并将原始数据转换为张量格式的步骤。\n",
    "我们将在后面的章节中介绍更多的数据预处理技术。\n",
    "\n",
    "## 读取数据集\n",
    "\n",
    "举一个例子，我们首先(**创建一个人工数据集，并存储在CSV（逗号分隔值）文件**)\n",
    "`../data/house_tiny.csv`中。\n",
    "以其他格式存储的数据也可以通过类似的方式进行处理。\n",
    "下面我们将数据集按行写入CSV文件中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3485a3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.120836Z",
     "iopub.status.busy": "2022-07-31T02:47:43.120587Z",
     "iopub.status.idle": "2022-07-31T02:47:43.130058Z",
     "shell.execute_reply": "2022-07-31T02:47:43.129398Z"
    },
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # 列名\n",
    "    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95605a32",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "要[**从创建的CSV文件中加载原始数据集**]，我们导入`pandas`包并调用`read_csv`函数。该数据集有四行三列。其中每行描述了房间数量（“NumRooms”）、巷子类型（“Alley”）和房屋价格（“Price”）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d067bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.133316Z",
     "iopub.status.busy": "2022-07-31T02:47:43.132861Z",
     "iopub.status.idle": "2022-07-31T02:47:43.561131Z",
     "shell.execute_reply": "2022-07-31T02:47:43.560442Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "# 如果没有安装pandas，只需取消对以下行的注释来安装pandas\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b841e4",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 处理缺失值\n",
    "\n",
    "注意，“NaN”项代表缺失值。\n",
    "[**为了处理缺失的数据，典型的方法包括*插值法*和*删除法*，**]\n",
    "其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。\n",
    "在(**这里，我们将考虑插值法**)。\n",
    "\n",
    "通过位置索引`iloc`，我们将`data`分成`inputs`和`outputs`，\n",
    "其中前者为`data`的前两列，而后者为`data`的最后一列。\n",
    "对于`inputs`中缺少的数值，我们用同一列的均值替换“NaN”项。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feb87e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.564342Z",
     "iopub.status.busy": "2022-07-31T02:47:43.563959Z",
     "iopub.status.idle": "2022-07-31T02:47:43.571872Z",
     "shell.execute_reply": "2022-07-31T02:47:43.571249Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs, outputs \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m], data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfillna(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10515\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  10517\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  10518\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 10519\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10520\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\frame.py:10482\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  10480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m  10481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 10482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9920a8",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "[**对于`inputs`中的类别值或离散值，我们将“NaN”视为一个类别。**]\n",
    "由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”，\n",
    "`pandas`可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。\n",
    "巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。\n",
    "缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228a5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.574819Z",
     "iopub.status.busy": "2022-07-31T02:47:43.574477Z",
     "iopub.status.idle": "2022-07-31T02:47:43.584160Z",
     "shell.execute_reply": "2022-07-31T02:47:43.583511Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       NaN        True      False\n",
      "1       2.0       False       True\n",
      "2       4.0       False       True\n",
      "3       NaN       False       True\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467868c",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## 转换为张量格式\n",
    "\n",
    "[**现在`inputs`和`outputs`中的所有条目都是数值类型，它们可以转换为张量格式。**]\n",
    "当数据采用张量格式后，可以通过在 :numref:`sec_ndarray`中引入的那些张量函数来进一步操作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6487a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.586980Z",
     "iopub.status.busy": "2022-07-31T02:47:43.586638Z",
     "iopub.status.idle": "2022-07-31T02:47:44.148381Z",
     "shell.execute_reply": "2022-07-31T02:47:44.147694Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f9257",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## 小结\n",
    "\n",
    "* `pandas`软件包是Python中常用的数据分析工具中，`pandas`可以与张量兼容。\n",
    "* 用`pandas`处理缺失的数据时，我们可根据情况选择用插值法和删除法。\n",
    "\n",
    "## 练习\n",
    "\n",
    "创建包含更多行和列的原始数据集。\n",
    "\n",
    "1. 删除缺失值最多的列。\n",
    "2. 将预处理后的数据集转换为张量格式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767d60f",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1750)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1: 删除缺失值最多的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -0.015513  0.987501       NaN -0.605282 -0.701734 -0.099767  1.257978   \n",
      "1 -0.901195 -1.234905       NaN  1.770638  1.482054  0.652315  1.768960   \n",
      "2  0.221328 -1.267129       NaN  2.063324  0.473436 -1.129048 -0.016930   \n",
      "3 -0.942942 -0.345627       NaN  0.852064  3.194468 -0.923525 -1.558210   \n",
      "4  0.464142  0.208140       NaN -0.239391 -0.286764  0.617788 -0.141047   \n",
      "5  1.975781  0.289483       NaN -0.440630       NaN  0.842304 -1.913303   \n",
      "6 -0.340146 -0.522074       NaN  0.481840       NaN  0.145274 -0.048020   \n",
      "7 -2.011562 -0.750059       NaN -0.506647       NaN  0.654894  0.606140   \n",
      "8 -0.028590  1.341047 -0.176699  0.255683 -1.546740  0.928226  0.961546   \n",
      "9 -0.345890  0.881455  1.883897 -0.139259 -0.726079 -0.393077  0.154864   \n",
      "\n",
      "          7         8         9  \n",
      "0  0.132332  0.339589  0.540579  \n",
      "1 -1.622314 -1.052288 -0.226541  \n",
      "2 -2.772317  0.087229  1.705030  \n",
      "3  2.856729 -0.374625  1.120645  \n",
      "4  1.548423 -0.852276 -0.935815  \n",
      "5  0.930299 -0.932507  0.917962  \n",
      "6 -2.097038  1.126206 -0.491510  \n",
      "7 -0.665785  0.889131 -0.312973  \n",
      "8       NaN -0.690886  0.912300  \n",
      "9       NaN -0.815219 -2.145733  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 建立一個100行10列的資料集\n",
    "raw_data = pd.DataFrame(np.random.randn(10,10)) \n",
    "\n",
    "# 在2,4,7列中加入缺失值\n",
    "raw_data.iloc[:8,2] = np.nan\n",
    "raw_data.iloc[5:8,4] = np.nan \n",
    "raw_data.iloc[8:,7] = np.nan\n",
    "\n",
    "# 統計每列的缺失值個數\n",
    "missing_count = raw_data.isnull().sum()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 取得缺失值最多的那一列\n",
    "most_missing_col = missing_count[missing_count==missing_count.max()].index[0] \n",
    "print(most_missing_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         3         4         5         6         7  \\\n",
      "0  0.848236 -0.604565 -2.125199 -0.561131  0.666404 -0.357414  0.719475   \n",
      "1 -0.763982  1.264226  1.527255  0.405355  1.365731  2.482153  0.418386   \n",
      "2 -0.316437 -0.597054 -1.050982 -0.301949 -0.793415 -0.061573 -0.840920   \n",
      "3  0.358027 -0.045710  0.806148  0.125088  0.068384  0.827972 -1.436924   \n",
      "4 -0.791207 -0.439528 -0.679347 -1.923081 -0.041273 -0.643833 -2.245317   \n",
      "5 -0.047117  0.286936 -0.282733       NaN -0.149701  0.274552  0.317985   \n",
      "6 -0.031458 -0.537391  0.708874  0.147732 -0.103467 -2.248026  0.137485   \n",
      "7 -1.047800  1.035614 -0.647511  1.889346  0.223507 -0.597081  0.184199   \n",
      "8  0.172889 -0.822085  0.037135  1.085364 -0.903427  1.255189       NaN   \n",
      "9 -0.235407  0.925761 -0.870109 -0.888770 -0.198729 -1.198686       NaN   \n",
      "\n",
      "          8         9  \n",
      "0  0.097712 -0.730359  \n",
      "1  1.988654  1.372115  \n",
      "2  2.921052 -2.159848  \n",
      "3  0.650842 -0.570485  \n",
      "4 -2.684897  0.596402  \n",
      "5 -0.516841  1.087877  \n",
      "6  0.595283 -1.996094  \n",
      "7 -0.832018  0.851183  \n",
      "8 -1.548414  0.120485  \n",
      "9  0.371715  0.050460  \n"
     ]
    }
   ],
   "source": [
    "# 删除缺失值最多的那一列\n",
    "raw_data.drop(most_missing_col,axis=1,inplace=True)\n",
    "\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0155,  0.9875,     nan, -0.6053, -0.7017, -0.0998,  1.2580,  0.1323,\n",
      "          0.3396,  0.5406],\n",
      "        [-0.9012, -1.2349,     nan,  1.7706,  1.4821,  0.6523,  1.7690, -1.6223,\n",
      "         -1.0523, -0.2265],\n",
      "        [ 0.2213, -1.2671,     nan,  2.0633,  0.4734, -1.1290, -0.0169, -2.7723,\n",
      "          0.0872,  1.7050],\n",
      "        [-0.9429, -0.3456,     nan,  0.8521,  3.1945, -0.9235, -1.5582,  2.8567,\n",
      "         -0.3746,  1.1206],\n",
      "        [ 0.4641,  0.2081,     nan, -0.2394, -0.2868,  0.6178, -0.1410,  1.5484,\n",
      "         -0.8523, -0.9358],\n",
      "        [ 1.9758,  0.2895,     nan, -0.4406,     nan,  0.8423, -1.9133,  0.9303,\n",
      "         -0.9325,  0.9180],\n",
      "        [-0.3401, -0.5221,     nan,  0.4818,     nan,  0.1453, -0.0480, -2.0970,\n",
      "          1.1262, -0.4915],\n",
      "        [-2.0116, -0.7501,     nan, -0.5066,     nan,  0.6549,  0.6061, -0.6658,\n",
      "          0.8891, -0.3130],\n",
      "        [-0.0286,  1.3410, -0.1767,  0.2557, -1.5467,  0.9282,  0.9615,     nan,\n",
      "         -0.6909,  0.9123],\n",
      "        [-0.3459,  0.8815,  1.8839, -0.1393, -0.7261, -0.3931,  0.1549,     nan,\n",
      "         -0.8152, -2.1457]], dtype=torch.float64)\n",
      "tensor([[-0.0155,  0.9875,     nan, -0.6053, -0.7017, -0.0998,  1.2580,  0.1323,\n",
      "          0.3396,  0.5406],\n",
      "        [-0.9012, -1.2349,     nan,  1.7706,  1.4821,  0.6523,  1.7690, -1.6223,\n",
      "         -1.0523, -0.2265],\n",
      "        [ 0.2213, -1.2671,     nan,  2.0633,  0.4734, -1.1290, -0.0169, -2.7723,\n",
      "          0.0872,  1.7050],\n",
      "        [-0.9429, -0.3456,     nan,  0.8521,  3.1945, -0.9235, -1.5582,  2.8567,\n",
      "         -0.3746,  1.1206],\n",
      "        [ 0.4641,  0.2081,     nan, -0.2394, -0.2868,  0.6178, -0.1410,  1.5484,\n",
      "         -0.8523, -0.9358],\n",
      "        [ 1.9758,  0.2895,     nan, -0.4406,     nan,  0.8423, -1.9133,  0.9303,\n",
      "         -0.9325,  0.9180],\n",
      "        [-0.3401, -0.5221,     nan,  0.4818,     nan,  0.1453, -0.0480, -2.0970,\n",
      "          1.1262, -0.4915],\n",
      "        [-2.0116, -0.7501,     nan, -0.5066,     nan,  0.6549,  0.6061, -0.6658,\n",
      "          0.8891, -0.3130],\n",
      "        [-0.0286,  1.3410, -0.1767,  0.2557, -1.5467,  0.9282,  0.9615,     nan,\n",
      "         -0.6909,  0.9123],\n",
      "        [-0.3459,  0.8815,  1.8839, -0.1393, -0.7261, -0.3931,  0.1549,     nan,\n",
      "         -0.8152, -2.1457]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X, y = torch.tensor(raw_data.values), torch.tensor(raw_data.values)\n",
    "print(X)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb58b8a5e356064d77409275aa6a1f162b9032006fbcb9d1859e2cbba12e0ad9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
