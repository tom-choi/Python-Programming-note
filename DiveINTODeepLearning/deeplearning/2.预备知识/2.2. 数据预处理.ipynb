{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abeac49d",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 数据预处理\n",
    ":label:`sec_pandas`\n",
    "\n",
    "为了能用深度学习来解决现实世界的问题，我们经常从预处理原始数据开始，\n",
    "而不是从那些准备好的张量格式数据开始。\n",
    "在Python中常用的数据分析工具中，我们通常使用`pandas`软件包。\n",
    "像庞大的Python生态系统中的许多其他扩展包一样，`pandas`可以与张量兼容。\n",
    "本节我们将简要介绍使用`pandas`预处理原始数据，并将原始数据转换为张量格式的步骤。\n",
    "我们将在后面的章节中介绍更多的数据预处理技术。\n",
    "\n",
    "## 读取数据集\n",
    "\n",
    "举一个例子，我们首先(**创建一个人工数据集，并存储在CSV（逗号分隔值）文件**)\n",
    "`../data/house_tiny.csv`中。\n",
    "以其他格式存储的数据也可以通过类似的方式进行处理。\n",
    "下面我们将数据集按行写入CSV文件中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3485a3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.120836Z",
     "iopub.status.busy": "2022-07-31T02:47:43.120587Z",
     "iopub.status.idle": "2022-07-31T02:47:43.130058Z",
     "shell.execute_reply": "2022-07-31T02:47:43.129398Z"
    },
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # 列名\n",
    "    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95605a32",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "要[**从创建的CSV文件中加载原始数据集**]，我们导入`pandas`包并调用`read_csv`函数。该数据集有四行三列。其中每行描述了房间数量（“NumRooms”）、巷子类型（“Alley”）和房屋价格（“Price”）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d067bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.133316Z",
     "iopub.status.busy": "2022-07-31T02:47:43.132861Z",
     "iopub.status.idle": "2022-07-31T02:47:43.561131Z",
     "shell.execute_reply": "2022-07-31T02:47:43.560442Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "# 如果没有安装pandas，只需取消对以下行的注释来安装pandas\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b841e4",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 处理缺失值\n",
    "\n",
    "注意，“NaN”项代表缺失值。\n",
    "[**为了处理缺失的数据，典型的方法包括*插值法*和*删除法*，**]\n",
    "其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。\n",
    "在(**这里，我们将考虑插值法**)。\n",
    "\n",
    "通过位置索引`iloc`，我们将`data`分成`inputs`和`outputs`，\n",
    "其中前者为`data`的前两列，而后者为`data`的最后一列。\n",
    "对于`inputs`中缺少的数值，我们用同一列的均值替换“NaN”项。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9feb87e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.564342Z",
     "iopub.status.busy": "2022-07-31T02:47:43.563959Z",
     "iopub.status.idle": "2022-07-31T02:47:43.571872Z",
     "shell.execute_reply": "2022-07-31T02:47:43.571249Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\github\\Python-Programming-note\\DiveINTODeepLearning\\deeplearning\\2.预备知识\\2.2. 数据预处理.ipynb 儲存格 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/Python-Programming-note/DiveINTODeepLearning/deeplearning/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/2.2.%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inputs, outputs \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m], data\u001b[39m.\u001b[39miloc[:, \u001b[39m2\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/github/Python-Programming-note/DiveINTODeepLearning/deeplearning/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/2.2.%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mfillna(inputs\u001b[39m.\u001b[39;49mmean())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/github/Python-Programming-note/DiveINTODeepLearning/deeplearning/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/2.2.%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(inputs)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\frame.py:11338\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11330\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m  11331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11332\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11336\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11337\u001b[0m ):\n\u001b[1;32m> 11338\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mmean(axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m  11339\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11340\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\generic.py:11969\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11963\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  11964\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11967\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11968\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m> 11969\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stat_function(\n\u001b[0;32m  11970\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m  11971\u001b[0m     )\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\generic.py:11926\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11922\u001b[0m nv\u001b[39m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11924\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m> 11926\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  11927\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[0;32m  11928\u001b[0m )\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\frame.py:11207\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11203\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mT\n\u001b[0;32m  11205\u001b[0m \u001b[39m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11206\u001b[0m \u001b[39m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11207\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreduce(blk_func)\n\u001b[0;32m  11208\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor_from_mgr(res, axes\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m  11209\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m out\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mreduce(func)\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[39m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[39m=\u001b[39m Index([\u001b[39mNone\u001b[39;00m])  \u001b[39m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(\u001b[39mself\u001b[39m, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[39m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[39m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[39m=\u001b[39m result\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\frame.py:11139\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11137\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([result])\n\u001b[0;32m  11138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m> 11139\u001b[0m     \u001b[39mreturn\u001b[39;00m op(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, mask\u001b[39m=\u001b[39mmask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum)\n\u001b[0;32m    720\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32md:\\python3.10.7\\lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9920a8",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "[**对于`inputs`中的类别值或离散值，我们将“NaN”视为一个类别。**]\n",
    "由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”，\n",
    "`pandas`可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。\n",
    "巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。\n",
    "缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e228a5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.574819Z",
     "iopub.status.busy": "2022-07-31T02:47:43.574477Z",
     "iopub.status.idle": "2022-07-31T02:47:43.584160Z",
     "shell.execute_reply": "2022-07-31T02:47:43.583511Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       NaN        True      False\n",
      "1       2.0       False       True\n",
      "2       4.0       False       True\n",
      "3       NaN       False       True\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467868c",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## 转换为张量格式\n",
    "\n",
    "[**现在`inputs`和`outputs`中的所有条目都是数值类型，它们可以转换为张量格式。**]\n",
    "当数据采用张量格式后，可以通过在 :numref:`sec_ndarray`中引入的那些张量函数来进一步操作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6487a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:47:43.586980Z",
     "iopub.status.busy": "2022-07-31T02:47:43.586638Z",
     "iopub.status.idle": "2022-07-31T02:47:44.148381Z",
     "shell.execute_reply": "2022-07-31T02:47:44.147694Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f9257",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## 小结\n",
    "\n",
    "* `pandas`软件包是Python中常用的数据分析工具中，`pandas`可以与张量兼容。\n",
    "* 用`pandas`处理缺失的数据时，我们可根据情况选择用插值法和删除法。\n",
    "\n",
    "## 练习\n",
    "\n",
    "创建包含更多行和列的原始数据集。\n",
    "\n",
    "1. 删除缺失值最多的列。\n",
    "2. 将预处理后的数据集转换为张量格式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767d60f",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1750)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題1: 删除缺失值最多的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.089604  0.737606       NaN -0.813122  0.016740  1.041876 -0.554007   \n",
      "1 -0.951437  0.079575       NaN -0.380885  0.594517 -0.273405  0.243241   \n",
      "2 -0.489010 -0.942634       NaN -0.272143 -0.480395 -0.593877 -1.161195   \n",
      "3 -0.278576 -0.414861       NaN  0.007159 -1.404076 -0.207324  1.593478   \n",
      "4 -1.836826  0.180240       NaN  0.012615  1.471118  0.141673  0.524310   \n",
      "5  0.380813  2.671936       NaN  1.601793       NaN  1.458587 -0.579347   \n",
      "6 -0.559325  0.581682       NaN  1.558354       NaN  1.888063 -0.527195   \n",
      "7 -1.323071 -0.917318       NaN -3.315996       NaN -0.288532  1.529429   \n",
      "8 -2.114200 -0.807402  1.741899  0.006645  0.649047  0.102802 -1.428705   \n",
      "9  0.208017  1.124217  0.640780 -0.011292 -0.674760 -1.324886  0.536741   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.294467 -1.231803  0.205720  \n",
      "1 -1.332085  1.222034 -0.161186  \n",
      "2  0.577695 -0.220094 -1.133463  \n",
      "3  0.393448 -3.273221  0.782935  \n",
      "4  0.483581 -1.186388 -0.098576  \n",
      "5 -0.526052 -3.066281 -0.000396  \n",
      "6 -0.722182 -0.873649  0.970586  \n",
      "7  0.651608  1.197651  1.413208  \n",
      "8       NaN -0.329324  0.365230  \n",
      "9       NaN  1.121134  0.590088  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 建立一個100行10列的資料集\n",
    "raw_data = pd.DataFrame(np.random.randn(10,10)) \n",
    "\n",
    "# 在2,4,7列中加入缺失值\n",
    "raw_data.iloc[:8,2] = np.nan\n",
    "raw_data.iloc[5:8,4] = np.nan \n",
    "raw_data.iloc[8:,7] = np.nan\n",
    "\n",
    "# 統計每列的缺失值個數\n",
    "missing_count = raw_data.isnull().sum()\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 取得缺失值最多的那一列\n",
    "most_missing_col = missing_count[missing_count==missing_count.max()].index[0] \n",
    "print(most_missing_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         3         4         5         6         7  \\\n",
      "0  0.848236 -0.604565 -2.125199 -0.561131  0.666404 -0.357414  0.719475   \n",
      "1 -0.763982  1.264226  1.527255  0.405355  1.365731  2.482153  0.418386   \n",
      "2 -0.316437 -0.597054 -1.050982 -0.301949 -0.793415 -0.061573 -0.840920   \n",
      "3  0.358027 -0.045710  0.806148  0.125088  0.068384  0.827972 -1.436924   \n",
      "4 -0.791207 -0.439528 -0.679347 -1.923081 -0.041273 -0.643833 -2.245317   \n",
      "5 -0.047117  0.286936 -0.282733       NaN -0.149701  0.274552  0.317985   \n",
      "6 -0.031458 -0.537391  0.708874  0.147732 -0.103467 -2.248026  0.137485   \n",
      "7 -1.047800  1.035614 -0.647511  1.889346  0.223507 -0.597081  0.184199   \n",
      "8  0.172889 -0.822085  0.037135  1.085364 -0.903427  1.255189       NaN   \n",
      "9 -0.235407  0.925761 -0.870109 -0.888770 -0.198729 -1.198686       NaN   \n",
      "\n",
      "          8         9  \n",
      "0  0.097712 -0.730359  \n",
      "1  1.988654  1.372115  \n",
      "2  2.921052 -2.159848  \n",
      "3  0.650842 -0.570485  \n",
      "4 -2.684897  0.596402  \n",
      "5 -0.516841  1.087877  \n",
      "6  0.595283 -1.996094  \n",
      "7 -0.832018  0.851183  \n",
      "8 -1.548414  0.120485  \n",
      "9  0.371715  0.050460  \n"
     ]
    }
   ],
   "source": [
    "# 删除缺失值最多的那一列\n",
    "raw_data.drop(most_missing_col,axis=1,inplace=True)\n",
    "\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb58b8a5e356064d77409275aa6a1f162b9032006fbcb9d1859e2cbba12e0ad9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
